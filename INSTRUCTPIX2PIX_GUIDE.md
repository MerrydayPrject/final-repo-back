# InstructPix2Pix ì‚¬ìš© ê°€ì´ë“œ

## 1. ì„¤ì¹˜

### í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
pip install diffusers transformers accelerate torch torchvision pillow
```

### requirements.txtì— ì¶”ê°€
```
diffusers>=0.21.0
transformers>=4.35.0
accelerate>=0.24.0
torch>=2.0.0
torchvision>=0.15.0
pillow>=10.0.0
```

### âš ï¸ ì¤‘ìš”: í•™ìŠµ ë¶ˆí•„ìš”!
- **ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©**: í•™ìŠµ(fine-tuning) ì—†ì´ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥
- **ìë™ ë‹¤ìš´ë¡œë“œ**: `from_pretrained()` í˜¸ì¶œ ì‹œ ìë™ìœ¼ë¡œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 2.5GB)
- **ì²« ì‹¤í–‰ ì‹œ**: ì¸í„°ë„· ì—°ê²° í•„ìš” (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ)
- **ì´í›„ ì‚¬ìš©**: ë‹¤ìš´ë¡œë“œëœ ëª¨ë¸ ìºì‹œ ì‚¬ìš© (ì¬ë‹¤ìš´ë¡œë“œ ë¶ˆí•„ìš”)

## 2. ê¸°ë³¸ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì½”ë“œ
```python
from diffusers import StableDiffusionInstructPix2PixPipeline
import torch
from PIL import Image

# ëª¨ë¸ ë¡œë“œ
pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(
    "timbrooks/instruct-pix2pix",
    torch_dtype=torch.float16,
    safety_checker=None,
    requires_safety_checker=False
)

# GPU ì‚¬ìš© ì‹œ
if torch.cuda.is_available():
    pipe = pipe.to("cuda")
else:
    pipe = pipe.to("cpu")

# ì´ë¯¸ì§€ í¸ì§‘
image = Image.open("composed_image.png").convert("RGB")
prompt = "make shoulders narrower and more natural"
result = pipe(prompt, image=image, num_inference_steps=20, image_guidance_scale=1.5).images[0]
result.save("edited_image.png")
```

## 3. InstructPix2Pixë¡œ ê°€ëŠ¥í•œ ê¸°ëŠ¥ë“¤

### âœ… ê°€ëŠ¥í•œ í¸ì§‘ ê¸°ëŠ¥
InstructPix2PixëŠ” ë‹¨ìˆœí•œ í˜•íƒœ ì¡°ì‘ë¿ë§Œ ì•„ë‹ˆë¼ **ìŠ¤íƒ€ì¼, ë¶„ìœ„ê¸°, ë°°ê²½ ë³€ê²½**ë„ ê°€ëŠ¥í•©ë‹ˆë‹¤!

#### 1. í˜•íƒœ ì¡°ì‘
- "make shoulders narrower" - ì–´ê¹¨ ì¢ê²Œ
- "make waist thinner" - í—ˆë¦¬ ì–‡ê²Œ
- "make the person taller" - í‚¤ í¬ê²Œ

#### 2. ìŠ¤íƒ€ì¼ ë³€ê²½
- "change to casual style" - ìºì£¼ì–¼ ìŠ¤íƒ€ì¼ë¡œ
- "make it more elegant" - ë” ìš°ì•„í•˜ê²Œ
- "change to vintage style" - ë¹ˆí‹°ì§€ ìŠ¤íƒ€ì¼ë¡œ
- "make it modern" - ëª¨ë˜í•˜ê²Œ

#### 3. ë¶„ìœ„ê¸° ë³€ê²½
- "make the mood more romantic" - ë” ë¡œë§¨í‹±í•˜ê²Œ
- "change to bright and cheerful atmosphere" - ë°ê³  ê²½ì¾Œí•œ ë¶„ìœ„ê¸°ë¡œ
- "make it more dramatic" - ë” ë“œë¼ë§ˆí‹±í•˜ê²Œ
- "change to warm and cozy feeling" - ë”°ëœ»í•˜ê³  ì•„ëŠ‘í•œ ëŠë‚Œìœ¼ë¡œ

#### 4. ë°°ê²½ ë³€ê²½
- "change background to beach" - ë°°ê²½ì„ í•´ë³€ìœ¼ë¡œ
- "change background to garden" - ë°°ê²½ì„ ì •ì›ìœ¼ë¡œ
- "make background blur" - ë°°ê²½ ë¸”ëŸ¬ ì²˜ë¦¬
- "remove background and add studio background" - ë°°ê²½ ì œê±° í›„ ìŠ¤íŠœë””ì˜¤ ë°°ê²½

#### 5. ì¡°ëª…/ìƒ‰ê° ë³€ê²½
- "make lighting more soft" - ì¡°ëª…ì„ ë” ë¶€ë“œëŸ½ê²Œ
- "change to warm lighting" - ë”°ëœ»í•œ ì¡°ëª…ìœ¼ë¡œ
- "make colors more vibrant" - ìƒ‰ê°ì„ ë” ì„ ëª…í•˜ê²Œ
- "change to black and white" - í‘ë°±ìœ¼ë¡œ

#### 6. ì „ì²´ì ì¸ í’ˆì§ˆ í–¥ìƒ
- "make it more realistic" - ë” í˜„ì‹¤ì ìœ¼ë¡œ
- "improve image quality" - ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒ
- "make it more professional" - ë” ì „ë¬¸ì ìœ¼ë¡œ

### ì‹¤ì œ ì‚¬ìš© ì˜ˆì‹œ
```python
# í˜•íƒœ ì¡°ì‘
result = pipe("make shoulders narrower", image=image).images[0]

# ìŠ¤íƒ€ì¼ ë³€ê²½
result = pipe("change to elegant wedding dress style", image=image).images[0]

# ë¶„ìœ„ê¸° ë³€ê²½
result = pipe("make the mood more romantic with soft lighting", image=image).images[0]

# ë°°ê²½ ë³€ê²½
result = pipe("change background to beautiful garden with flowers", image=image).images[0]

# ë³µí•© ìš”ì²­
result = pipe("make shoulders narrower, change to elegant style, and make background blur", image=image).images[0]
```

## 4. í•œêµ­ì–´ ìš”ì²­ì„ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜

### ë³€í™˜ í•¨ìˆ˜ (í™•ì¥ ë²„ì „)
```python
def translate_korean_to_prompt(korean_text):
    """í•œêµ­ì–´ ìš”ì²­ì„ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜"""
    
    # í˜•íƒœ ì¡°ì‘ ë§¤í•‘
    shape_mappings = {
        "ì–´ê¹¨ê°€ ë„ˆë¬´ ë„“ê²Œ": "make shoulders narrower",
        "ì–´ê¹¨ë¥¼ ì¢ê²Œ": "make shoulders narrower",
        "í—ˆë¦¬ë¥¼ ì–‡ê²Œ": "make waist thinner",
        "ì—‰ë©ì´ë¥¼ ì‘ê²Œ": "make hips smaller",
    }
    
    # ìŠ¤íƒ€ì¼ ë³€ê²½ ë§¤í•‘
    style_mappings = {
        "ìš°ì•„í•˜ê²Œ": "make it more elegant",
        "ìºì£¼ì–¼í•˜ê²Œ": "change to casual style",
        "ëª¨ë˜í•˜ê²Œ": "make it more modern",
        "ë¹ˆí‹°ì§€": "change to vintage style",
        "í´ë˜ì‹": "change to classic style",
    }
    
    # ë¶„ìœ„ê¸° ë³€ê²½ ë§¤í•‘
    mood_mappings = {
        "ë¡œë§¨í‹±í•˜ê²Œ": "make the mood more romantic",
        "ë°ê²Œ": "make it bright and cheerful",
        "ë“œë¼ë§ˆí‹±í•˜ê²Œ": "make it more dramatic",
        "ë”°ëœ»í•˜ê²Œ": "change to warm and cozy feeling",
    }
    
    # ë°°ê²½ ë³€ê²½ ë§¤í•‘
    background_mappings = {
        "ë°°ê²½ì„ í•´ë³€ìœ¼ë¡œ": "change background to beach",
        "ë°°ê²½ì„ ì •ì›ìœ¼ë¡œ": "change background to garden",
        "ë°°ê²½ ë¸”ëŸ¬": "make background blur",
        "ë°°ê²½ ì œê±°": "remove background",
    }
    
    # ëª¨ë“  ë§¤í•‘ ê²€ì‚¬
    prompt_parts = []
    
    for kor, eng in {**shape_mappings, **style_mappings, **mood_mappings, **background_mappings}.items():
        if kor in korean_text:
            prompt_parts.append(eng)
    
    if prompt_parts:
        return ", ".join(prompt_parts) + " and make it more natural"
    else:
        # ê¸°ë³¸ ë³€í™˜
        return f"adjust {korean_text} to make it more natural and realistic"
```

## 4. FastAPI ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„ ì˜ˆì‹œ

### main.pyì— ì¶”ê°€
```python
from diffusers import StableDiffusionInstructPix2PixPipeline
import torch
from PIL import Image
import io
import base64

# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ ì €ì¥
instruct_pix2pix_pipe = None

def load_instruct_pix2pix_model():
    """InstructPix2Pix ëª¨ë¸ ë¡œë“œ"""
    global instruct_pix2pix_pipe
    if instruct_pix2pix_pipe is None:
        print("InstructPix2Pix ëª¨ë¸ ë¡œë”© ì¤‘...")
        instruct_pix2pix_pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(
            "timbrooks/instruct-pix2pix",
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,
            safety_checker=None,
            requires_safety_checker=False
        )
        device = "cuda" if torch.cuda.is_available() else "cpu"
        instruct_pix2pix_pipe = instruct_pix2pix_pipe.to(device)
        print(f"InstructPix2Pix ëª¨ë¸ ë¡œë“œ ì™„ë£Œ: {device}")
    return instruct_pix2pix_pipe

def translate_korean_request(korean_text):
    """í•œêµ­ì–´ ìš”ì²­ì„ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜ (í™•ì¥ ë²„ì „)"""
    
    # í˜•íƒœ ì¡°ì‘
    shape_mappings = {
        "ì–´ê¹¨ê°€ ë„ˆë¬´ ë„“ê²Œ": "make shoulders narrower",
        "ì–´ê¹¨ë¥¼ ì¢ê²Œ": "make shoulders narrower",
        "í—ˆë¦¬ë¥¼ ì–‡ê²Œ": "make waist thinner",
        "ì—‰ë©ì´ë¥¼ ì‘ê²Œ": "make hips smaller",
        "íŒ”ì„ ì§§ê²Œ": "make arms shorter",
        "ë‹¤ë¦¬ë¥¼ ê¸¸ê²Œ": "make legs longer",
    }
    
    # ìŠ¤íƒ€ì¼ ë³€ê²½
    style_mappings = {
        "ìš°ì•„í•˜ê²Œ": "make it more elegant",
        "ìºì£¼ì–¼í•˜ê²Œ": "change to casual style",
        "ëª¨ë˜í•˜ê²Œ": "make it more modern",
        "ë¹ˆí‹°ì§€": "change to vintage style",
    }
    
    # ë¶„ìœ„ê¸° ë³€ê²½
    mood_mappings = {
        "ë¡œë§¨í‹±í•˜ê²Œ": "make the mood more romantic",
        "ë°ê²Œ": "make it bright and cheerful",
        "ë“œë¼ë§ˆí‹±í•˜ê²Œ": "make it more dramatic",
    }
    
    # ë°°ê²½ ë³€ê²½
    background_mappings = {
        "ë°°ê²½ì„ í•´ë³€ìœ¼ë¡œ": "change background to beach",
        "ë°°ê²½ì„ ì •ì›ìœ¼ë¡œ": "change background to garden",
        "ë°°ê²½ ë¸”ëŸ¬": "make background blur",
    }
    
    # ëª¨ë“  ë§¤í•‘ ë³‘í•©
    all_mappings = {**shape_mappings, **style_mappings, **mood_mappings, **background_mappings}
    
    # ë§¤ì¹­ëœ í”„ë¡¬í”„íŠ¸ ìˆ˜ì§‘
    prompt_parts = []
    for kor, eng in all_mappings.items():
        if kor in korean_text:
            prompt_parts.append(eng)
    
    if prompt_parts:
        return ", ".join(prompt_parts) + " and make it more natural"
    else:
        return f"adjust {korean_text} to make it more natural and realistic"

@app.post("/api/enhance-image")
async def enhance_image(
    file: UploadFile = File(...),
    instruction: str = Form(""),  # ì‚¬ìš©ì ìš”ì²­ í…ìŠ¤íŠ¸
    num_inference_steps: int = Form(20),
    image_guidance_scale: float = Form(1.5)
):
    """
    ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ ì´ë¯¸ì§€ ë³´ì •
    
    - file: í•©ì„±ëœ ì´ë¯¸ì§€
    - instruction: ì‚¬ìš©ì ìš”ì²­ (ì˜ˆ: "ì–´ê¹¨ê°€ ë„ˆë¬´ ë„“ê²Œ ë‚˜ì™”ì–´, ì¢ê²Œ ìˆ˜ì •í•´ì¤˜")
    - num_inference_steps: ì¶”ë¡  ë‹¨ê³„ (20-50, ë†’ì„ìˆ˜ë¡ í’ˆì§ˆ ì¢‹ì§€ë§Œ ëŠë¦¼)
    - image_guidance_scale: ì´ë¯¸ì§€ ê°€ì´ë˜ìŠ¤ (1.0-2.0, ë†’ì„ìˆ˜ë¡ ì›ë³¸ ìœ ì§€)
    """
    try:
        # ì´ë¯¸ì§€ ì½ê¸°
        image_bytes = await file.read()
        image = Image.open(io.BytesIO(image_bytes)).convert("RGB")
        
        # í•œêµ­ì–´ ìš”ì²­ì„ ì˜ì–´ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
        if instruction:
            prompt = translate_korean_request(instruction)
        else:
            prompt = "make the image more natural and realistic"
        
        # ëª¨ë¸ ë¡œë“œ
        pipe = load_instruct_pix2pix_model()
        
        # ì´ë¯¸ì§€ í¸ì§‘
        result_image = pipe(
            prompt,
            image=image,
            num_inference_steps=num_inference_steps,
            image_guidance_scale=image_guidance_scale
        ).images[0]
        
        # Base64ë¡œ ë³€í™˜
        buffered = io.BytesIO()
        result_image.save(buffered, format="PNG")
        img_base64 = base64.b64encode(buffered.getvalue()).decode()
        
        return JSONResponse({
            "success": True,
            "result_image": f"data:image/png;base64,{img_base64}",
            "prompt_used": prompt,
            "message": "ì´ë¯¸ì§€ ë³´ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
        })
        
    except Exception as e:
        return JSONResponse({
            "success": False,
            "error": str(e),
            "message": f"ì´ë¯¸ì§€ ë³´ì • ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        }, status_code=500)
```

## 5. ì‚¬ìš© ì˜ˆì‹œ

### í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜¸ì¶œ
```javascript
// api.jsì— ì¶”ê°€
export const enhanceImage = async (imageFile, instruction) => {
    try {
        const formData = new FormData()
        formData.append('file', imageFile)
        formData.append('instruction', instruction)
        formData.append('num_inference_steps', 20)
        formData.append('image_guidance_scale', 1.5)
        
        const response = await api.post('/api/enhance-image', formData, {
            headers: {
                'Content-Type': 'multipart/form-data',
            },
        })
        
        return response.data
    } catch (error) {
        console.error('ì´ë¯¸ì§€ ë³´ì • ì˜¤ë¥˜:', error)
        throw error
    }
}

// ì‚¬ìš© ì˜ˆì‹œ
const result = await enhanceImage(
    imageFile, 
    "ì–´ê¹¨ê°€ ë„ˆë¬´ ë„“ê²Œ ë‚˜ì™”ì–´, ì¢ê²Œ ìˆ˜ì •í•´ì¤˜"
)
```

## 6. íŒŒë¼ë¯¸í„° ì„¤ëª…

### num_inference_steps
- **ë²”ìœ„**: 10-50 (ê¸°ë³¸ê°’: 20)
- **ì„¤ëª…**: ì¶”ë¡  ë‹¨ê³„ ìˆ˜
- **íš¨ê³¼**: ë†’ì„ìˆ˜ë¡ í’ˆì§ˆì´ ì¢‹ì•„ì§€ì§€ë§Œ ì²˜ë¦¬ ì‹œê°„ì´ ê¸¸ì–´ì§
- **ì¶”ì²œ**: 20-30

### image_guidance_scale
- **ë²”ìœ„**: 1.0-2.0 (ê¸°ë³¸ê°’: 1.5)
- **ì„¤ëª…**: ì›ë³¸ ì´ë¯¸ì§€ ìœ ì§€ ì •ë„
- **íš¨ê³¼**: 
  - ë‚®ìŒ (1.0-1.2): ë” ë§ì´ ë³€ê²½, ì°½ì˜ì 
  - ë†’ìŒ (1.5-2.0): ì›ë³¸ ìœ ì§€, ì•ˆì •ì 
- **ì¶”ì²œ**: 1.5

## 7. ì£¼ì˜ì‚¬í•­

### GPU ë©”ëª¨ë¦¬
- **ìµœì†Œ ìš”êµ¬ì‚¬í•­**: 8GB VRAM
- **ê¶Œì¥**: 16GB+ VRAM
- **CPU ì‚¬ìš© ì‹œ**: ë§¤ìš° ëŠë¦¼ (ê¶Œì¥í•˜ì§€ ì•ŠìŒ)

### ì²˜ë¦¬ ì‹œê°„
- **GPU**: ì•½ 5-10ì´ˆ (20 steps ê¸°ì¤€)
- **CPU**: ì•½ 1-3ë¶„ (20 steps ê¸°ì¤€)

### ëª¨ë¸ í¬ê¸°
- **ë‹¤ìš´ë¡œë“œ í¬ê¸°**: ì•½ 2.5GB
- **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: ì•½ 4-6GB

## 8. ìµœì í™” íŒ

### ë°°ì¹˜ ì²˜ë¦¬
```python
# ì—¬ëŸ¬ ì´ë¯¸ì§€ë¥¼ í•œ ë²ˆì— ì²˜ë¦¬ (GPU ë©”ëª¨ë¦¬ í—ˆìš© ì‹œ)
results = pipe(prompt, image=[img1, img2, img3], num_inference_steps=20)
```

### ëª¨ë¸ ìºì‹±
```python
# ì „ì—­ ë³€ìˆ˜ë¡œ ëª¨ë¸ì„ í•œ ë²ˆë§Œ ë¡œë“œí•˜ê³  ì¬ì‚¬ìš©
# ìœ„ì˜ load_instruct_pix2pix_model() í•¨ìˆ˜ ì°¸ì¡°
```

### ì €í•´ìƒë„ ì²˜ë¦¬ í›„ ì—…ìŠ¤ì¼€ì¼
```python
# 1. ì €í•´ìƒë„ë¡œ ë¹ ë¥´ê²Œ í¸ì§‘
small_image = image.resize((512, 512))
result = pipe(prompt, image=small_image, num_inference_steps=10)

# 2. Real-ESRGANìœ¼ë¡œ ì—…ìŠ¤ì¼€ì¼
# (ë³„ë„ ê°€ì´ë“œ ì°¸ì¡°)
```

## 9. ì—ëŸ¬ ì²˜ë¦¬

### ì¼ë°˜ì ì¸ ì—ëŸ¬
```python
try:
    result = pipe(prompt, image=image)
except torch.cuda.OutOfMemoryError:
    # GPU ë©”ëª¨ë¦¬ ë¶€ì¡±
    # ì´ë¯¸ì§€ í¬ê¸° ì¤„ì´ê¸° ë˜ëŠ” CPU ì‚¬ìš©
    image = image.resize((512, 512))
    result = pipe(prompt, image=image)
except Exception as e:
    print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
```

## 10. í”„ë¡œì íŠ¸ í†µí•© ì˜ˆì‹œ

### main.pyì— í†µí•©
```python
# ì•± ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ
@app.on_event("startup")
async def startup_event():
    # ê¸°ì¡´ ëª¨ë¸ë“¤ ë¡œë“œ
    load_model()
    init_database()
    
    # InstructPix2Pix ëª¨ë¸ ë¡œë“œ (ì„ íƒì )
    try:
        load_instruct_pix2pix_model()
        print("âœ… InstructPix2Pix ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
    except Exception as e:
        print(f"âš ï¸ InstructPix2Pix ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
```

### requirements.txtì— ì¶”ê°€
```
diffusers>=0.21.0
transformers>=4.35.0
accelerate>=0.24.0
```

## 11. í…ŒìŠ¤íŠ¸ ì½”ë“œ

```python
# test_instruct_pix2pix.py
from PIL import Image
from diffusers import StableDiffusionInstructPix2PixPipeline
import torch

pipe = StableDiffusionInstructPix2PixPipeline.from_pretrained(
    "timbrooks/instruct-pix2pix",
    torch_dtype=torch.float16
).to("cuda")

image = Image.open("test_image.png").convert("RGB")

# ë‹¤ì–‘í•œ í…ŒìŠ¤íŠ¸
test_prompts = [
    "make shoulders narrower",  # í˜•íƒœ ì¡°ì‘
    "change to elegant wedding dress style",  # ìŠ¤íƒ€ì¼ ë³€ê²½
    "make the mood more romantic with soft lighting",  # ë¶„ìœ„ê¸° ë³€ê²½
    "change background to beautiful garden",  # ë°°ê²½ ë³€ê²½
    "make it more realistic and professional",  # í’ˆì§ˆ í–¥ìƒ
]

for i, prompt in enumerate(test_prompts):
    result = pipe(prompt, image=image, num_inference_steps=20).images[0]
    result.save(f"result_{i+1}.png")
    print(f"í…ŒìŠ¤íŠ¸ {i+1} ì™„ë£Œ: {prompt}")

print("ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
```

## 12. ìŠ¤íƒ€ì¼/ë¶„ìœ„ê¸° ë³€ê²½ì— ëŒ€í•œ ì œí•œì‚¬í•­

### âš ï¸ ì£¼ì˜ì‚¬í•­
- **í˜•íƒœ ì¡°ì‘**: ë¹„êµì  ì •í™•í•˜ê²Œ ì‘ë™
- **ìŠ¤íƒ€ì¼ ë³€ê²½**: ì¼ë°˜ì ìœ¼ë¡œ ì˜ ì‘ë™í•˜ì§€ë§Œ ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ê³¼ ì°¨ì´ê°€ ìˆì„ ìˆ˜ ìˆìŒ
- **ë°°ê²½ ë³€ê²½**: ê°„ë‹¨í•œ ë°°ê²½ì€ ì˜ ì‘ë™, ë³µì¡í•œ ë°°ê²½ì€ ì œí•œì 
- **ë¶„ìœ„ê¸° ë³€ê²½**: ì¡°ëª…/ìƒ‰ê° ë³€ê²½ì€ ì˜ ì‘ë™, ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ëŠ” ì œí•œì 

### ğŸ’¡ ë” ì •í™•í•œ ìŠ¤íƒ€ì¼ ë³€ê²½ì„ ì›í•œë‹¤ë©´
- **ControlNet**: í¬ì¦ˆ/êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ìŠ¤íƒ€ì¼ ë³€ê²½
- **IP-Adapter**: ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ì„ ì°¸ì¡°í•˜ì—¬ ë³€ê²½
- **Stable Diffusion Inpainting**: íŠ¹ì • ì˜ì—­ë§Œ ì„ íƒì ìœ¼ë¡œ ë³€ê²½

## 13. ì‹¤ì œ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: í˜•íƒœ + ìŠ¤íƒ€ì¼ ë™ì‹œ ë³€ê²½
```python
prompt = "make shoulders narrower and change to elegant wedding dress style"
result = pipe(prompt, image=image, num_inference_steps=25, image_guidance_scale=1.5).images[0]
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë¶„ìœ„ê¸° + ë°°ê²½ ë³€ê²½
```python
prompt = "make the mood more romantic with soft lighting and change background to garden"
result = pipe(prompt, image=image, num_inference_steps=25).images[0]
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë³µí•© ìš”ì²­
```python
prompt = "make waist thinner, change to modern style, make background blur, and improve image quality"
result = pipe(prompt, image=image, num_inference_steps=30, image_guidance_scale=1.5).images[0]
```

